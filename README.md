# Bruno_PDFLLM
Bruno is an AI application that can leverage the power of **Retrieval Augmented Generation** to let the user **Chat with a PDF**. Try our Bruno and share your experience!

![image](https://github.com/thru-goes-hamilton/Bruno_PDFLLM/assets/114722386/969b5942-3033-4ce6-8f4a-cb83ae2b2b32)
![image](https://github.com/thru-goes-hamilton/Bruno_PDFLLM/assets/114722386/b2f9d270-96d8-4349-9666-c336a113b129)


## Features
- Extract information from a PDF document
- Summarizing, Titling and other creative writing tasks based on uploaded PDF
- Answer logical questions about the information in the uploaded PDF
## How to Use
- Upload any PDF file on your system using the Browse Files button
- Enter any prompt
- Press the Sumbit button to get your answer
- Enter subsequent prompts and press Submit again
## RAG
Retrieval Augmented Generation (RAG) combines the capabilities of a **large language model** with a **vector-based retrieval system** to generate responses. The LLM uses relevant information retrieved from PDFs to provide accurate and contextually meaningful answers to user prompts.<br>
## Step-by-Step Explanation of RAG in Bruno
- ### Extracting Text from PDF
  Uses ```PyPDF2``` to extract text from each page of a provided PDF file, combining it into a single string.
- ### Setting up LLM
  Sets up an instance of GradientBaseModelLLM using the ```llama2-7b-chat``` model, provided by the Gradient platform
- ### Setting up Embedding Model
  Sets up an instance of GradientEmbedding using the ```bge-large``` model, an embedding model used for vector representations.
- ### Document Loading
  The extracted text from the PDF is loaded as a Document object with a metadata field "name": "PDF Document".
- ### Vector Store Index and Query Engine
  A VectorStoreIndex is created from the Document objects, which is a data structure that stores the text and its corresponding vector representations. A query engine allows querying the index using natural language prompts.
- ### Querying the Index
  The query engine is queried with the provided prompt, and the response is stored.
- ### Extracting Refined Answer
  The extract_refined_answer function is called that searches for specific patterns in the text to extract the "refined answer" generated by the LLM.
<br>
![image](https://github.com/thru-goes-hamilton/Bruno_PDFLLM/assets/114722386/52614c59-d6b8-46b2-9ab1-02a1122855ae)
Llama2 7b

## Application
- Custom UI/UX for Chatbot
- Built using the Streamlit framework
- State management to display multiple prompts and answer
